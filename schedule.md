---
layout: page
title: Schedule
permalink: /schedule/
---


### Spring 2020

Below are the the topics we aim to cover but time and the order might change.


| Week          | Tuesday       | Thursday   | Thursday Section | References  (optional)| Assignment  |
|:--------------|:--------------------|:-------------------|:-------------------|:-------------|:------------
|1. March 30 |Intro to Machine Learning<br>[slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec1?preview=63527606)| Linear Regression, Assessing Performance <br> [slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec02?preview=63576180), [colab](https://colab.research.google.com/drive/1zHaXZnh35ab99puBpj8Gpik7GGo0Qh9M)| Pandas<br>[exercises](https://drive.google.com/a/uw.edu/file/d/1RCUHIos_-Rvk9wwj_G24rFmpQe3veC55/view?usp=sharing), [solutions](https://drive.google.com/a/uw.edu/file/d/1wXMMJQnaXvMr_1pnU23JD0NK8_LJ_TvW/view?usp=sharing), [slides](https://canvas.uw.edu/courses/1371982/files/folder/Labs/lab1?preview=63588246)| [PyDS] [Intro](https://jakevdp.github.io/PythonDataScienceHandbook/05.01-what-is-machine-learning.html), [Linear Regression](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html); [[ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)] Section 1, 2.3.1 |[HW0]({{base.url}}../homework#HW0) due April 8th|
|2. April 6| Bias/Variance Trade-off <br> [slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec03)| Regularization, Ridge Regression<br>[slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec04),[colab](https://colab.research.google.com/drive/1F1C-nhmiZISCFpNCVMIeSjclZo8DhA_6)|Gradient Descent<br>[colab](https://drive.google.com/a/uw.edu/file/d/1DMQjNNLQKxlXmlpVOVayRNIq-Wzcd0LK/view?usp=sharing),<br>[slides](https://canvas.uw.edu/courses/1371982/files/folder/Labs/lab2?preview=63815132),<br> [calculus](https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/optimizing-multivariable-functions/a/maximums-minimums-and-saddle-points) |[PyDS] [Model Selection](https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html), [Regularization](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Regularization); [[ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)] Section 7.1-7.4, 3.4.1 | [HW1]({{base.url}}../homework#HW1) due April 15th|
|3. April 13| Feature Selection, Lasso Regression <br> [slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec05),[colab](https://colab.research.google.com/drive/1ok6Ze8Fqs2T4L1LVpbSHfn0e9cAppczb)| Classification Overview <br>[slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec06)  | Bias Var & Ridge Lasso<br>[slides](https://drive.google.com/open?id=1sTyaU0nakDqTyNL_fb7tgnPecnCRstpF)<br> [colab](https://drive.google.com/open?id=1_a9NSS535Pa_S1umDpQffPKD64mcaNAm)|[[ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)]  Section 3.4.2-3.4.3 | [HW2]({{base.url}}../homework#HW2) due April 22th |
|4. April 20| Evaluation Metrics, Logistic Regression <br>[slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec07)| Naive Bayes <br>[slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec08)| Logistic Regression [colab](https://drive.google.com/a/uw.edu/file/d/1KPoOacrsV4OC08MOclw2UZywOjRlnQJF/view?usp=sharing) |[[ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)] Section 4.1, 4.4.1-4.4.4, 9.1.2, 9.2.5, 6.6.3, [ROC/PR Curves](https://www.biostat.wisc.edu/~page/rocpr.pdf), [Scikit-Learn Reference](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html), [[PyDS] Naive Bayes](https://jakevdp.github.io/PythonDataScienceHandbook/05.05-naive-bayes.html)|[HW3]({{base.url}}../homework#HW3) due April 30th |
|5. April 27| Decision Trees <br> [slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec09)| Ensemble Methods | |[[ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)] Section 9.2.1-9.2.3,[[PyDS](https://jakevdp.github.io/PythonDataScienceHandbook/05.08-random-forests.html)]
|6. May 4 |Kernel Methods| 
|7. May 11| Neural Networks| Convolutional Neural Networks, Transfer Learning|
|8. May 18| Nearest Neighbors, K-means | Assessment, Hierarchical Clustering
|9. May 25|Dimensionality Reduction <br> PCA, NMF| Nonlinear Embeddings
|10. June 1 |Reinforcement Learning | Ethics|

{: rules="groups"}

