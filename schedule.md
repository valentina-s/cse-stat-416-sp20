---
layout: page
title: Schedule
permalink: /schedule/
---


### Spring 2020

Below are the the topics we aim to cover but time and the order might change.


| Week          | Tuesday       | Thursday   | Thursday Section | References  (optional)| Assignment  |
|:--------------|:--------------------|:-------------------|:-------------------|:-------------|:------------
|1. March 30 |Intro to Machine Learning<br>[slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec1?preview=63527606)| Linear Regression, Assessing Performance <br> [slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec02?preview=63576180), [colab](https://colab.research.google.com/drive/1zHaXZnh35ab99puBpj8Gpik7GGo0Qh9M)| Pandas<br>[exercises](https://drive.google.com/a/uw.edu/file/d/1RCUHIos_-Rvk9wwj_G24rFmpQe3veC55/view?usp=sharing), [solutions](https://drive.google.com/a/uw.edu/file/d/1wXMMJQnaXvMr_1pnU23JD0NK8_LJ_TvW/view?usp=sharing), [slides](https://canvas.uw.edu/courses/1371982/files/folder/Labs/lab1?preview=63588246)| [PyDS] [Intro](https://jakevdp.github.io/PythonDataScienceHandbook/05.01-what-is-machine-learning.html), [Linear Regression](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html); [[ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)] Section 1, 2.3.1 |[HW0]({{base.url}}../homework#HW0) due April 8th|
|2. April 6| Bias/Variance Trade-off <br> [slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec03)| Regularization, Ridge Regression<br>[slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec04),[colab](https://colab.research.google.com/drive/1F1C-nhmiZISCFpNCVMIeSjclZo8DhA_6)|Gradient Descent<br>[colab](https://drive.google.com/a/uw.edu/file/d/1DMQjNNLQKxlXmlpVOVayRNIq-Wzcd0LK/view?usp=sharing),<br>[slides](https://canvas.uw.edu/courses/1371982/files/folder/Labs/lab2?preview=63815132),<br> [calculus](https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/optimizing-multivariable-functions/a/maximums-minimums-and-saddle-points) |[PyDS] [Model Selection](https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html), [Regularization](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Regularization); [[ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)] Section 7.1-7.4, 3.4.1 | [HW1]({{base.url}}../homework#HW1) due April 15th|
|3. April 13| Feature Selection, Lasso Regression <br> [slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec05),[colab](https://colab.research.google.com/drive/1ok6Ze8Fqs2T4L1LVpbSHfn0e9cAppczb)| Classification Overview <br>[slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec06)  | Bias Var & Ridge Lasso<br>[slides](https://drive.google.com/open?id=1sTyaU0nakDqTyNL_fb7tgnPecnCRstpF)<br> [colab](https://drive.google.com/open?id=1_a9NSS535Pa_S1umDpQffPKD64mcaNAm)|[[ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)]  Section 3.4.2-3.4.3 | [HW2]({{base.url}}../homework#HW2) due April 22th |
|4. April 20| Evaluation Metrics, Logistic Regression <br>[slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec07)| Naive Bayes <br>[slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec08)| Logistic Regression [colab](https://drive.google.com/a/uw.edu/file/d/1KPoOacrsV4OC08MOclw2UZywOjRlnQJF/view?usp=sharing) |[[ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)] Section 4.1, 4.4.1-4.4.4, 9.1.2, 9.2.5, 6.6.3, [ROC/PR Curves](https://www.biostat.wisc.edu/~page/rocpr.pdf), [Scikit-Learn Reference](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html), [[PyDS] Naive Bayes](https://jakevdp.github.io/PythonDataScienceHandbook/05.05-naive-bayes.html)|[HW3]({{base.url}}../homework#HW3) due April 30th 
|5. April 27| Decision Trees <br> [slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec09)| Ensemble Methods <br> [slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec10)|Random Forest ðŸ˜† <br> [Random Forest Slides](https://drive.google.com/open?id=1sbTnRA-oo8qswMHAgGXnyGlgDiL7h0iJ), [Gini Impurity Slides](https://drive.google.com/open?id=1SUGhaBbx17GA2uL1ooBw9xCy8xDSmyFh), [Random Forest colab](https://drive.google.com/open?id=1kKvhzyjpiqa6zeir4I8rCMh2UBLbp8WO), [Titanic colab](https://drive.google.com/open?id=1-4BZ-kqdFHHIGxxFdw5geVfWFJynhScO) |[[ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)] Section 9.2.1-9.2.3,15.1-15.3.2, 10.1,[[PyDS](https://jakevdp.github.io/PythonDataScienceHandbook/05.08-random-forests.html)]| [HW4]({{base.url}}../homework#HW4) due May 7th|
|6. May 5| Nearest Neighbors <br> [slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec11)|Kernel Methods <br>[slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec12)| Method Review <br> [Colab](https://drive.google.com/open?id=1mDFWkJ7TCQMCjt2GlvX6bKYTGon2Lgts) , [Topics Sheet](https://drive.google.com/open?id=1XwCuoQ-jeI17Y74DtNczItzJ1-tbybwdP228Ob-KKpc), [Variable Encoding Colab](https://drive.google.com/open?id=1y_8Y0_hGS4IAPsTyjX3wJly8wd5e5Vzv) |[[ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)] Section 13.3,  [Scikit-Learn Reference](https://scikit-learn.org/stable/modules/neighbors.html), [CV for groups and time series](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators-for-grouped-data)|[HW5]({{base.url}}../homework#HW5) due May 14th
|7. May 11| Neural Networks <br> [slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec13)| Convolutional Neural Networks, Transfer Learning <br> [slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec14)| Keras & CNN <br> [slides](https://canvas.uw.edu/courses/1371982/files/folder/Labs/lab7?preview=65285241),<br> [blog slides](https://drive.google.com/open?id=1fj453u9iNKTR78dFvYqZJAByWsmQxLv1), <br> [cnn_notebook](https://drive.google.com/open?id=1iccoUX-HumXNxcCRXW-7msh3vZdwJ6_0),<br> [nn_notebook](https://drive.google.com/open?id=1WzM0eSogowR6bVqIrvE55wS4-OyRJ87F)|[Neural Networks Intro](https://cs231n.github.io/neural-networks-1/), [CNN Intro](https://cs231n.github.io/convolutional-networks/), [Deep Forward Networks](https://www.deeplearningbook.org/contents/mlp.html), [Convolutional Neural Networks](https://www.deeplearningbook.org/contents/convnets.html)| [HW6]({{base.url}}../homework#HW6) due May 21st|
|8. May 18| K-means <br> [slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec15)| Assessment, Hierarchical Clustering <br> [slides](https://canvas.uw.edu/courses/1371982/files/folder/Lectures/lec16)|Unsupervised Learning :) <br> [colab](https://drive.google.com/open?id=1Ol1jRWYce7WXNLky3Y7_n4wiCTv2llBf)||
|9. May 25|Dimensionality Reduction <br> PCA, NMF| Nonlinear Embeddings
|10. June 1 |Reinforcement Learning | Ethics|

{: rules="groups"}

